{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import python NLTK modules (based on examples from www.nltk.org/howto/sentiment.html)\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# The text we'll be working with is the first few paragraphs of \"Alice in Wonderland\" by Lewis Carroll\n",
    "text = \"\"\"Alice was beginning to get very tired of sitting by her sister on the\n",
    "bank, and of having nothing to do: once or twice she had peeped into the\n",
    "book her sister was reading, but it had no pictures or conversations in\n",
    "it, 'and what is the use of a book,' thought Alice 'without pictures or\n",
    "conversations?'\n",
    "\n",
    "So she was considering in her own mind (as well as she could, for the\n",
    "hot day made her feel very sleepy and stupid), whether the pleasure\n",
    "of making a daisy-chain would be worth the trouble of getting up and\n",
    "picking the daisies, when suddenly a White Rabbit with pink eyes ran\n",
    "close by her.\n",
    "\n",
    "There was nothing so VERY remarkable in that; nor did Alice think it so\n",
    "VERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\n",
    "Oh dear! I shall be late!' (when she thought it over afterwards, it\n",
    "occurred to her that she ought to have wondered at this, but at the time\n",
    "it all seemed quite natural); but when the Rabbit actually TOOK A WATCH\n",
    "OUT OF ITS WAISTCOAT-POCKET, and looked at it, and then hurried on,\n",
    "Alice started to her feet, for it flashed across her mind that she had\n",
    "never before seen a rabbit with either a waistcoat-pocket, or a watch\n",
    "to take out of it, and burning with curiosity, she ran across the field\n",
    "after it, and fortunately was just in time to see it pop down a large\n",
    "rabbit-hole under the hedge.\"\"\"\n",
    "\n",
    "# Remove newlines\n",
    "text = re.sub(\"\\n\", \" \", text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Once again, we need to tokenize the text into sentences in order to perform any kind of analysis on it\n",
    "tokenized_text = sent_tokenize(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we can attempt to analyze the intensity of each sentence\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for sentence in tokenized_text:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print '{0}: {1}, '.format(k, ss[k]),\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import additional NLTK modules for more complex sentiment analysis task\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build training data sets\n",
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:100]]\n",
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:100]]\n",
    "training_docs = subj_docs[:80] + obj_docs[:80]\n",
    "print(training_docs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build test data sets (to be replaced with new example)\n",
    "test_docs = subj_docs[80:100] + obj_docs[80:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build and prepare sentiment analyzer\n",
    "sentiment_analyzer = SentimentAnalyzer()\n",
    "all_words_neg = sentiment_analyzer.all_words([mark_negation(doc) for doc in training_docs])\n",
    "unigram_feats = sentiment_analyzer.unigram_word_feats(all_words_neg, min_freq = 4)\n",
    "sentiment_analyzer.add_feat_extractor(extract_unigram_feats, unigrams = unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we can apply our sentiment analyzer model to our data sets' features\n",
    "training_set = sentiment_analyzer.apply_features(training_docs)\n",
    "test_set = sentiment_analyzer.apply_features(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now it's time to train the model\n",
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentiment_analyzer.train(trainer, training_set)\n",
    "for key, value in sorted(sentiment_analyzer.evaluate(test_set).items()):\n",
    "    print  '{0}: {1}'.format(key, value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
